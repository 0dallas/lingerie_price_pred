{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-aiplatform \\\n",
    "#                         google-cloud-storage \\\n",
    "#                         kfp \\\n",
    "#                         google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"mimetic-card-436014-r9\"  \n",
    "\n",
    "# !gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"europe-west4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://price_lingerie_predict_eu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = '93305744778-compute@developer.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wrfig\\AppData\\Local\\Temp\\ipykernel_20132\\721882072.py:4: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "import typing\n",
    "import json\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        component,\n",
    "                        OutputPath,\n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer data y dividir entrenamiento/prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas\",\n",
    "                         \"google-cloud-storage\",\n",
    "                         \"scikit-learn==1.5.2\"],\n",
    "    base_image=\"python:3.9\",\n",
    "\n",
    ")\n",
    "def get_data_storage(\n",
    "    path: str,\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    ") -> NamedTuple(\"GetDataOutput\",[(\"product_category_dict\",str),(\"brand_name_dict\",str),(\"color_dict\",str)]):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from google.cloud import storage\n",
    "    import json\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket_name, blob_name = path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    temp_file = \"/tmp/temp.csv\"\n",
    "    blob.download_to_filename(temp_file)\n",
    "\n",
    "    df = pd.read_csv(temp_file)\n",
    "\n",
    "    train, test = train_test_split(df,test_size=0.3)\n",
    "\n",
    "    product_category_dict = dict()\n",
    "    brand_name_dict = dict()\n",
    "    color_dict = dict()\n",
    "\n",
    "    for i,j in enumerate(train['product_category'].unique().tolist()):\n",
    "        product_category_dict[j] = i\n",
    "    train['product_category'] = train['product_category'].map(product_category_dict)\n",
    "    test['product_category'] = test['product_category'].map(product_category_dict)\n",
    "\n",
    "    for i,j in enumerate(train['brand_name'].unique().tolist()):\n",
    "        brand_name_dict[j] = i\n",
    "    train['brand_name'] = train['brand_name'].map(brand_name_dict)\n",
    "    test['brand_name'] = test['brand_name'].map(brand_name_dict)\n",
    "\n",
    "    for i,j in enumerate(train['color'].unique().tolist()):\n",
    "        color_dict[j] = i\n",
    "    train['color'] = train['color'].map(color_dict)\n",
    "    test['color'] = test['color'].map(color_dict)\n",
    "\n",
    "    train.to_csv(dataset_train.path + \".csv\", index=False)\n",
    "    test.to_csv(dataset_test.path + \".csv\", index=False)\n",
    "\n",
    "    return (json.dumps(product_category_dict),json.dumps(brand_name_dict),json.dumps(color_dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"scikit-learn==1.3.2\",\n",
    "                         \"numpy==1.22.4\",\n",
    "                         \"pandas\"],\n",
    "    base_image=\"python:3.10\",  \n",
    ")\n",
    "def train_model(\n",
    "    dataset: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "):\n",
    "\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    data = pd.read_csv(dataset.path +\".csv\")\n",
    "    model_rf = RandomForestRegressor(max_depth=30,\n",
    "                                  min_samples_split=6,\n",
    "                                  n_estimators=200,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    model_rf.fit(\n",
    "        data.drop(columns='price'),\n",
    "        data.price\n",
    "    )\n",
    "\n",
    "    score = model_rf.score(\n",
    "        data.drop(columns='price'),\n",
    "        data.price\n",
    "    )\n",
    "\n",
    "    model.metadata[\"train_score\"] = float(score)\n",
    "    model.metadata[\"framework\"] = 'RF'\n",
    "\n",
    "    joblib.dump(model_rf,model.path + \".joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"scikit-learn==1.3.2\",\n",
    "                         \"numpy==1.22.4\",\n",
    "                         \"pandas\"],\n",
    "    base_image=\"python:3.10\",\n",
    ")\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    rf_model: Input[Model],\n",
    "    metrics: Output[Metrics]\n",
    ") -> NamedTuple(\"EvalModelOutput\",[(\"deploy\",str)]):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "\n",
    "    data = pd.read_csv(test_set.path + '.csv')\n",
    "    model_path = rf_model.path + \".joblib\"\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    X_test = data.drop(columns='price')\n",
    "    y_test = data.price\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred,squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    metrics.log_metric('rmse', rmse)\n",
    "    metrics.log_metric('mae', mae)\n",
    "    metrics.log_metric('r2', r2)\n",
    "\n",
    "    deploy = 'true'\n",
    "\n",
    "    return(deploy,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despliegue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\",\n",
    "                         \"kfp\",\n",
    "                         \"scikit-learn==1.3.2\"],\n",
    "    base_image=\"python:3.10\",\n",
    ")\n",
    "def depl_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    serving_container_image_uri: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    import os\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    DISPLAY_NAME = \"lingerieprice\"\n",
    "    ENDPOINT_NAME = \"lingerieprice-endpoint\"\n",
    "\n",
    "    path, _ = os.path.split(model.uri)\n",
    "\n",
    "    upload_model = aiplatform.Model.upload(\n",
    "        display_name = DISPLAY_NAME,\n",
    "        artifact_uri = path,\n",
    "        serving_container_image_uri = serving_container_image_uri,  \n",
    "    )\n",
    "\n",
    "    def crear_endpoint():\n",
    "        endpoints = aiplatform.Endpoint.list(\n",
    "                filter=f'display_name=\"{ENDPOINT_NAME}\"',\n",
    "                order_by=\"create_time desc\",\n",
    "                project=project,\n",
    "                location=region)\n",
    "        \n",
    "        if len(endpoints) > 0:\n",
    "            return endpoints[0]\n",
    "        else:\n",
    "            return aiplatform.Endpoint.create(\n",
    "                display_name=ENDPOINT_NAME,\n",
    "                project=project,\n",
    "                location=region)\n",
    "        \n",
    "    endpoint = crear_endpoint()\n",
    "\n",
    "    deploy_model =  upload_model.deploy(\n",
    "        machine_type = \"n1-standard-4\",\n",
    "        endpoint = endpoint,\n",
    "        min_replica_count=1, \n",
    "        max_replica_count=3,   \n",
    "        deployed_model_display_name = DISPLAY_NAME\n",
    "    )\n",
    "\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deploy_model.resource_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://price_lingerie_predict_eu/pipeline/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wrfig\\AppData\\Local\\Temp\\ipykernel_20132\\2083098456.py:24: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name= \"pipeline-pricelignerie-2\"\n",
    ")\n",
    "def pipeline(\n",
    "    path: str = 'gs://price_lingerie_predict_eu/data/DATA_MODELO.csv',\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "    serving_container_image_uri: str = 'europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest'\n",
    "    \n",
    "):\n",
    "    \n",
    "    data_op = get_data_storage(path=path)\n",
    "    train_model_op = train_model(dataset=data_op.outputs['dataset_train'])\n",
    "    model_evaluation_op = eval_model(\n",
    "        test_set=data_op.outputs['dataset_test'],\n",
    "        rf_model=train_model_op.outputs['model']\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        model_evaluation_op.outputs['deploy'] == \"true\",\n",
    "        name=\"deploy\"\n",
    "    ):\n",
    "        deploy_model_op = depl_model(\n",
    "            model=train_model_op.outputs['model'],\n",
    "            project=project,\n",
    "            region=region,\n",
    "            serving_container_image_uri=serving_container_image_uri\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar y ejecutar pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"model_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"lingerieprice-pipeline\",\n",
    "    template_path=\"model_pipeline.json\",\n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west4/pipelines/runs/pipeline-pricelignerie-2-20250205225347?project=93305744778\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/93305744778/locations/europe-west4/pipelineJobs/pipeline-pricelignerie-2-20250205225347\n"
     ]
    }
   ],
   "source": [
    "job.run(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
